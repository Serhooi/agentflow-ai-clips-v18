# AgentFlow AI Clips v18.6.0 - –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ Remotion
import os
import json
import uuid
import asyncio
import logging
import subprocess
import tempfile
from datetime import datetime
from typing import Dict, List, Optional, Any
import psutil
import shutil

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
import openai
from openai import OpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–ü–ï–†–í–´–ú –î–ï–õ–û–ú!)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("app")

# Supabase Storage –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    logger.warning("Supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# Redis –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    import redis
    redis_client = redis.from_url(
        os.getenv("REDIS_URL", "redis://localhost:6379/0"),
        decode_responses=True
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    redis_client.ping()
    REDIS_AVAILABLE = True
    logger.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
except Exception as e:
    REDIS_AVAILABLE = False
    redis_client = None
    logger.warning(f"‚ö†Ô∏è Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="AgentFlow AI Clips API",
    description="–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏",
    version="18.6.0"
)

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 512MB RAM
class Config:
    UPLOAD_DIR = "uploads"
    AUDIO_DIR = "audio"
    CLIPS_DIR = "clips"
    MAX_FILE_SIZE = int(os.getenv("MAX_FILE_SIZE_MB", "250")) * 1024 * 1024  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ª–∏–º–∏—Ç
    MAX_TASK_AGE = 4 * 60 * 60  # 4 —á–∞—Å–∞ (–¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ)
    CLEANUP_INTERVAL = 600  # –û—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
    MAX_MEMORY_USAGE = 600 * 1024 * 1024  # 600MB –ª–∏–º–∏—Ç (–¥–ª—è –±–æ–ª—å—à–∏—Ö –≤–∏–¥–µ–æ)
    MAX_CONCURRENT_TASKS = 2  # –ú–∞–∫—Å–∏–º—É–º 2 –∑–∞–¥–∞—á–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
    CLIP_MIN_DURATION = int(os.getenv("CLIP_MIN_DURATION", "40"))  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–æ–≤
    CLIP_MAX_DURATION = int(os.getenv("CLIP_MAX_DURATION", "80"))  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–æ–≤
    FFMPEG_TIMEOUT_MULTIPLIER = int(os.getenv("FFMPEG_TIMEOUT_MULTIPLIER", "4"))  # –ú–Ω–æ–∂–∏—Ç–µ–ª—å —Ç–∞–π–º–∞—É—Ç–∞ –¥–ª—è ffmpeg
    CONTENT_LANGUAGE = os.getenv("CONTENT_LANGUAGE", "ru")  # –Ø–∑—ã–∫ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (ru/en)

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–ø–æ–∫
for directory in [Config.UPLOAD_DIR, Config.AUDIO_DIR, Config.CLIPS_DIR]:
    os.makedirs(directory, exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
analysis_tasks = {}
generation_tasks = {}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    logger.error("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    raise ValueError("OPENAI_API_KEY –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")

client = OpenAI(api_key=openai_api_key)
logger.info("‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase
supabase = None
service_supabase = None
SUPABASE_BUCKET = "video-results"

def init_supabase():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–æ–≤"""
    global supabase, service_supabase
    if not SUPABASE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    try:
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_anon_key = os.getenv("SUPABASE_ANON_KEY")
        supabase_service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        if not all([supabase_url, supabase_anon_key, supabase_service_key]):
            logger.warning("‚ö†Ô∏è –ù–µ –≤—Å–µ Supabase –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
            return False
        supabase = create_client(supabase_url, supabase_anon_key)
        service_supabase = create_client(supabase_url, supabase_service_key)
        logger.info("‚úÖ Supabase Storage –ø–æ–¥–∫–ª—é—á–µ–Ω")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return False

supabase_available = init_supabase()

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–∞–º—è—Ç–∏
def get_memory_usage() -> Dict[str, int]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏"""
    try:
        memory = psutil.virtual_memory()
        process = psutil.Process()
        return {
            "total_mb": memory.total // (1024 * 1024),
            "available_mb": memory.available // (1024 * 1024),
            "used_mb": memory.used // (1024 * 1024),
            "process_mb": process.memory_info().rss // (1024 * 1024),
            "percent": memory.percent
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏: {e}")
        return {"total_mb": 512, "available_mb": 100, "used_mb": 412, "process_mb": 50, "percent": 80}

def check_memory_limit() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –ø–∞–º—è—Ç–∏"""
    try:
        memory_info = get_memory_usage()
        if memory_info["process_mb"] > (Config.MAX_MEMORY_USAGE // (1024 * 1024)):
            logger.warning(f"‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–∞–º—è—Ç–∏: {memory_info['process_mb']}MB")
            return False
        return True
    except Exception:
        return True

def cleanup_old_files():
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –º–µ—Å—Ç–∞"""
    try:
        current_time = datetime.now()
        cleaned_count = 0
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≤–∏–¥–µ–æ
        for filename in os.listdir(Config.UPLOAD_DIR):
            file_path = os.path.join(Config.UPLOAD_DIR, filename)
            if os.path.isfile(file_path):
                file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                if (current_time - file_time).seconds > Config.MAX_TASK_AGE:
                    os.remove(file_path)
                    cleaned_count += 1
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤
        for filename in os.listdir(Config.AUDIO_DIR):
            file_path = os.path.join(Config.AUDIO_DIR, filename)
            if os.path.isfile(file_path):
                file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                if (current_time - file_time).seconds > Config.MAX_TASK_AGE:
                    os.remove(file_path)
                    cleaned_count += 1
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫–ª–∏–ø–æ–≤
        for filename in os.listdir(Config.CLIPS_DIR):
            file_path = os.path.join(Config.CLIPS_DIR, filename)
            if os.path.isfile(file_path):
                file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                if (current_time - file_time).seconds > Config.MAX_TASK_AGE:
                    os.remove(file_path)
                    cleaned_count += 1
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á –∏–∑ –ø–∞–º—è—Ç–∏
        tasks_to_remove = []
        for task_id, task in analysis_tasks.items():
            task_age = (current_time - task["created_at"]).seconds
            if task_age > Config.MAX_TASK_AGE:
                tasks_to_remove.append(task_id)
        
        for task_id in tasks_to_remove:
            del analysis_tasks[task_id]
            cleaned_count += 1
        
        if cleaned_count > 0:
            logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ {cleaned_count} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤/–∑–∞–¥–∞—á")
        
        return cleaned_count
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")
        return 0

# –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return {
        "name": "AgentFlow AI Clips API",
        "version": "18.6.0",
        "status": "running",
        "description": "–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤ —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏",
        "endpoints": {
            "upload": "/api/videos/upload",
            "analyze": "/api/videos/analyze", 
            "health": "/health",
            "stats": "/api/system/stats",
            "docs": "/docs"
        },
        "memory_optimized": "512MB RAM",
        "redis_available": REDIS_AVAILABLE
    }

# –î–æ–±–∞–≤–ª—è–µ–º —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
    try:
        memory_info = get_memory_usage()
        active_tasks = get_active_tasks_count()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ffmpeg
        ffmpeg_available = True
        try:
            subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True, timeout=5)
        except:
            ffmpeg_available = False
        
        return {
            "status": "healthy",
            "memory": memory_info,
            "active_tasks": active_tasks,
            "max_concurrent_tasks": Config.MAX_CONCURRENT_TASKS,
            "ffmpeg_available": ffmpeg_available,
            "supabase_available": supabase_available,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/system/stats")
async def get_system_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        memory_info = get_memory_usage()
        active_tasks = get_active_tasks_count()
        
        # –ü–æ–¥—Å—á–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–∞—Ö
        upload_files = len([f for f in os.listdir(Config.UPLOAD_DIR) if os.path.isfile(os.path.join(Config.UPLOAD_DIR, f))])
        audio_files = len([f for f in os.listdir(Config.AUDIO_DIR) if os.path.isfile(os.path.join(Config.AUDIO_DIR, f))])
        clip_files = len([f for f in os.listdir(Config.CLIPS_DIR) if os.path.isfile(os.path.join(Config.CLIPS_DIR, f))])
        
        return {
            "memory": memory_info,
            "tasks": {
                "active": active_tasks,
                "total": len(analysis_tasks),
                "max_concurrent": Config.MAX_CONCURRENT_TASKS
            },
            "files": {
                "uploads": upload_files,
                "audio": audio_files,
                "clips": clip_files
            },
            "config": {
                "max_file_size_mb": Config.MAX_FILE_SIZE // (1024 * 1024),
                "max_memory_mb": Config.MAX_MEMORY_USAGE // (1024 * 1024),
                "cleanup_interval_min": Config.CLEANUP_INTERVAL // 60,
                "max_task_age_hours": Config.MAX_TASK_AGE // 3600
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/system/cleanup")
async def manual_cleanup():
    """–†—É—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        cleaned_count = cleanup_old_files()
        memory_info = get_memory_usage()
        
        return {
            "cleaned_files": cleaned_count,
            "memory_after_cleanup": memory_info,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/system/queue-stats")
async def get_queue_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á"""
    try:
        queue_stats = hybrid_queue.get_queue_stats()
        memory_info = get_memory_usage()
        active_tasks = get_active_tasks_count()
        
        return {
            "queue": queue_stats,
            "memory": memory_info,
            "active_tasks": active_tasks,
            "redis_available": REDIS_AVAILABLE,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def get_active_tasks_count() -> int:
    """–ü–æ–¥—Å—á–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á"""
    active_count = 0
    for task in analysis_tasks.values():
        if task["status"] == "processing":
            active_count += 1
    return active_count

# –ì–∏–±—Ä–∏–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—á–µ—Ä–µ–¥–µ–π (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å Redis –∏ –±–µ–∑ –Ω–µ–≥–æ)
class HybridTaskQueue:
    """–ì–∏–±—Ä–∏–¥–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á - Redis –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ –ø–∞–º—è—Ç—å"""
    
    def __init__(self):
        self.queue_name = "video_processing_queue"
        self.processing_set = "processing_tasks"
        self.results_prefix = "task_result:"
        self.memory_queue = []  # Fallback –æ—á–µ—Ä–µ–¥—å –≤ –ø–∞–º—è—Ç–∏
        self.memory_processing = set()  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã–µ –∑–∞–¥–∞—á–∏
        self.memory_results = {}  # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–º—è—Ç–∏
    
    def add_task(self, task_data: Dict) -> str:
        """–î–æ–±–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å"""
        task_id = str(uuid.uuid4())
        task_data["task_id"] = task_id
        task_data["created_at"] = datetime.now().isoformat()
        
        if REDIS_AVAILABLE:
            try:
                redis_client.lpush(self.queue_name, json.dumps(task_data))
                logger.info(f"üìù –ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ Redis –æ—á–µ—Ä–µ–¥—å: {task_id}")
                return task_id
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Redis, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–º—è—Ç—å: {e}")
        
        # Fallback –≤ –ø–∞–º—è—Ç—å
        self.memory_queue.append(task_data)
        logger.info(f"üìù –ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –ø–∞–º—è—Ç—å: {task_id}")
        return task_id
    
    def get_task(self) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–∞–¥–∞—á—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏"""
        if REDIS_AVAILABLE:
            try:
                result = redis_client.brpop(self.queue_name, timeout=1)
                if result:
                    task_data = json.loads(result[1])
                    redis_client.sadd(self.processing_set, task_data["task_id"])
                    return task_data
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Redis: {e}")
        
        # Fallback –≤ –ø–∞–º—è—Ç—å
        if self.memory_queue:
            task_data = self.memory_queue.pop(0)
            self.memory_processing.add(task_data["task_id"])
            return task_data
        
        return None
    
    def complete_task(self, task_id: str, result: Dict):
        """–ó–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–¥–∞—á—É"""
        if REDIS_AVAILABLE:
            try:
                redis_client.setex(f"{self.results_prefix}{task_id}", 3600, json.dumps(result))
                redis_client.srem(self.processing_set, task_id)
                logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –≤ Redis: {task_id}")
                return
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Redis: {e}")
        
        # Fallback –≤ –ø–∞–º—è—Ç—å
        self.memory_results[task_id] = result
        self.memory_processing.discard(task_id)
        logger.info(f"‚úÖ –ó–∞–¥–∞—á–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –≤ –ø–∞–º—è—Ç–∏: {task_id}")
    
    def get_task_result(self, task_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞—á–∏"""
        if REDIS_AVAILABLE:
            try:
                result = redis_client.get(f"{self.results_prefix}{task_id}")
                if result:
                    return json.loads(result)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Redis: {e}")
        
        # Fallback –≤ –ø–∞–º—è—Ç—å
        return self.memory_results.get(task_id)
    
    def get_queue_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–µ—Ä–µ–¥–∏"""
        if REDIS_AVAILABLE:
            try:
                return {
                    "queue_length": redis_client.llen(self.queue_name),
                    "processing": redis_client.scard(self.processing_set),
                    "redis_available": True,
                    "mode": "redis"
                }
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Redis: {e}")
        
        # Fallback –≤ –ø–∞–º—è—Ç—å
        return {
            "queue_length": len(self.memory_queue),
            "processing": len(self.memory_processing),
            "redis_available": False,
            "mode": "memory"
        }

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –≥–∏–±—Ä–∏–¥–Ω–∞—è –æ—á–µ—Ä–µ–¥—å
hybrid_queue = HybridTaskQueue()

# Pydantic –º–æ–¥–µ–ª–∏
class VideoAnalysisRequest(BaseModel):
    video_id: str

class ClipGenerationRequest(BaseModel):
    video_id: str
    format_id: str

class VideoInfo(BaseModel):
    id: str
    filename: str
    duration: float
    size: int
    status: str
    upload_time: str

class ClipInfo(BaseModel):
    id: str
    video_id: str
    format_id: str
    status: str
    progress: int
    current_stage: Optional[str] = None
    stage_progress: Optional[int] = None

def upload_clip_to_supabase(local_path: str, filename: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∏–ø–∞ –≤ Supabase Storage"""
    if not supabase_available or not service_supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å")
        return f"/api/clips/download/{filename}"
    try:
        with open(local_path, "rb") as clip_file:
            storage_path = f"clips/{datetime.now().strftime('%Y%m%d')}/{filename}"
            response = service_supabase.storage.from_(SUPABASE_BUCKET).upload(
                storage_path, clip_file, {"content-type": "video/mp4"}
            )
            if response:
                public_url = service_supabase.storage.from_(SUPABASE_BUCKET).get_public_url(storage_path)
                logger.info(f"‚úÖ –ö–ª–∏–ø –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Supabase: {public_url}")
                return public_url
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Supabase: {e}")
    logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ")
    return f"/api/clips/download/{filename}"

def get_video_duration(video_path: str) -> float:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ"""
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video_path]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        return float(data['format']['duration'])
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ: {e}")
        return 60.0  # Fallback

def extract_audio(video_path: str, audio_path: str) -> bool:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è 512MB RAM)"""
    try:
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        cmd = [
            'ffmpeg', '-i', video_path, 
            '-vn',  # –ë–µ–∑ –≤–∏–¥–µ–æ
            '-acodec', 'mp3', 
            '-ar', '16000',  # –ù–∏–∑–∫–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            '-ac', '1',  # –ú–æ–Ω–æ
            '-ab', '64k',  # –ù–∏–∑–∫–∏–π –±–∏—Ç—Ä–µ–π—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            '-threads', '1',  # –û–¥–∏–Ω –ø–æ—Ç–æ–∫ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            '-y', audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=300)
        return os.path.exists(audio_path)
    except subprocess.TimeoutExpired:
        logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ")
        return False
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
        return False

def safe_transcribe_audio(audio_path: str) -> Optional[Dict]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤"""
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["word"],
                # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤ –∏ –º–µ–∂–¥–æ–º–µ—Ç–∏–π
                prompt="Transcribe everything including all filler words, hesitations, and interjections: um, uh, ah, oh, hmm, yeah, yep, yes, no, like, you know, I mean, so, well, actually, basically, literally, right, okay, alright, wow, hey, man, dude, guys, folks, people, anyway, whatever, honestly, seriously, obviously, definitely, probably, maybe, perhaps, indeed, certainly, absolutely, exactly, totally, completely, really, very, quite, just, only, even, still, already, yet, now, then, here, there, this, that, these, those."
            )
            result = transcript.model_dump() if hasattr(transcript, 'model_dump') else dict(transcript)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            diagnose_transcript_issues(result)
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤
            if 'words' in result:
                result['words'] = enhance_filler_words(result['words'])
            
            return result
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
        return None

def enhance_filler_words(words: List[Dict]) -> List[Dict]:
    """–£–ª—É—á—à–∞–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤ –∏ –º–µ–∂–¥–æ–º–µ—Ç–∏–π"""
    enhanced_words = []
    corrections_made = 0
    filler_words_found = 0
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Å—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤
    filler_corrections = {
        'um': ['uhm', 'umm', 'uum', 'em'],
        'uh': ['uhh', 'uuh', 'ah'],
        'yeah': ['yah', 'yea', 'ye'],
        'like': ['lyk', 'lik'],
        'you know': ['ya know', 'y\'know', 'yknow'],
        'so': ['soo', 'sooo'],
        'well': ['wel', 'wll'],
        'actually': ['actualy', 'acually'],
        'basically': ['basicaly', 'basicly'],
        'literally': ['literaly', 'literaly'],
        'right': ['rite', 'rght'],
        'okay': ['ok', 'okk', 'okey'],
        'alright': ['aright', 'alrite', 'all right'],
        'hmm': ['hm', 'hmm', 'hmmm'],
        'oh': ['ooh', 'ohh'],
        'wow': ['woow', 'wooow'],
        'hey': ['hei', 'heyy'],
        'man': ['mn'],
        'dude': ['dud'],
        'guys': ['gys'],
        'folks': ['folx'],
        'people': ['ppl', 'peple']
    }
    
    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
    all_filler_words = ['um', 'uh', 'yeah', 'like', 'you know', 'so', 'well', 'actually', 'basically', 'literally', 'right', 'okay', 'alright', 'hmm', 'oh', 'wow', 'hey', 'man', 'dude', 'guys', 'folks', 'people']
    
    for word in words:
        word_text = word.get('word', '').strip().lower()
        original_word = word_text
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Å–ª–æ–≤–æ
        corrected = False
        for correct_word, variations in filler_corrections.items():
            if word_text in variations:
                word['word'] = correct_word
                corrections_made += 1
                corrected = True
                logger.debug(f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: '{original_word}' ‚Üí '{correct_word}'")
                break
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å—Ç–∞–≤–Ω—ã–µ —Å–ª–æ–≤–∞
        if word_text in all_filler_words or any(word_text in variations for variations in filler_corrections.values()):
            filler_words_found += 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        enhanced_words.append(word)
    
    logger.info(f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(enhanced_words)} —Å–ª–æ–≤: {corrections_made} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π, {filler_words_found} –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ")
    return enhanced_words

def analyze_content_type(transcript_text: str) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ –∫–ª–∏–ø–æ–≤"""
    text_lower = transcript_text.lower()
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    educational_keywords = ['learn', 'teach', 'explain', 'understand', 'knowledge', 'study', 'lesson', 'course', 'tutorial', 'guide', 'how to', 'step by step', 'method', 'technique', 'process', 'theory', 'concept', 'principle', 'definition', 'example']
    entertainment_keywords = ['funny', 'hilarious', 'joke', 'laugh', 'comedy', 'entertainment', 'fun', 'amusing', 'humor', 'story', 'adventure', 'exciting', 'amazing', 'incredible', 'unbelievable', 'crazy', 'wild', 'epic', 'awesome', 'fantastic']
    business_keywords = ['business', 'money', 'profit', 'investment', 'strategy', 'marketing', 'sales', 'growth', 'success', 'entrepreneur', 'startup', 'company', 'market', 'customer', 'revenue', 'finance', 'economy', 'industry', 'competition', 'opportunity']
    personal_keywords = ['life', 'experience', 'personal', 'journey', 'story', 'challenge', 'overcome', 'struggle', 'achievement', 'goal', 'dream', 'motivation', 'inspiration', 'advice', 'wisdom', 'lesson learned', 'mistake', 'failure', 'success', 'growth']
    tech_keywords = ['technology', 'software', 'app', 'digital', 'internet', 'computer', 'programming', 'code', 'development', 'innovation', 'artificial intelligence', 'ai', 'machine learning', 'data', 'algorithm', 'system', 'platform', 'tool', 'feature', 'update']
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    educational_score = sum(1 for keyword in educational_keywords if keyword in text_lower)
    entertainment_score = sum(1 for keyword in entertainment_keywords if keyword in text_lower)
    business_score = sum(1 for keyword in business_keywords if keyword in text_lower)
    personal_score = sum(1 for keyword in personal_keywords if keyword in text_lower)
    tech_score = sum(1 for keyword in tech_keywords if keyword in text_lower)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    scores = {
        'educational': educational_score,
        'entertainment': entertainment_score,
        'business': business_score,
        'personal': personal_score,
        'tech': tech_score
    }
    
    content_type = max(scores, key=scores.get)
    logger.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {content_type} (score: {scores[content_type]})")
    
    return content_type

def analyze_content_value(transcript_text: str) -> Dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
    text_lower = transcript_text.lower()
    
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤—ã—Å–æ–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏
    value_indicators = {
        'actionable_advice': 0,
        'specific_numbers': 0,
        'personal_stories': 0,
        'expert_insights': 0,
        'problem_solutions': 0,
        'surprising_facts': 0,
        'practical_tips': 0,
        'emotional_moments': 0
    }
    
    # –°–ª–æ–≤–∞, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
    actionable_words = ['how to', 'step by step', 'here\'s what', 'you should', 'you need to', 'the key is', 'the secret is', 'what works', 'what doesn\'t work', 'avoid this', 'do this instead', 'try this', 'use this']
    value_indicators['actionable_advice'] = sum(1 for word in actionable_words if word in text_lower)
    
    # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —á–∏—Å–ª–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    import re
    numbers = re.findall(r'\b\d+(?:\.\d+)?(?:%|percent|million|billion|thousand|dollars?|years?|months?|days?|hours?|minutes?)\b', text_lower)
    value_indicators['specific_numbers'] = len(numbers)
    
    # –õ–∏—á–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –æ–ø—ã—Ç
    story_words = ['when i', 'i remember', 'my experience', 'what happened', 'i learned', 'i discovered', 'i realized', 'my mistake', 'i failed', 'i succeeded']
    value_indicators['personal_stories'] = sum(1 for word in story_words if word in text_lower)
    
    # –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã
    expert_words = ['research shows', 'studies prove', 'data reveals', 'according to', 'experts say', 'the truth is', 'what most people don\'t know', 'insider secret', 'industry secret']
    value_indicators['expert_insights'] = sum(1 for word in expert_words if word in text_lower)
    
    # –†–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º
    solution_words = ['solution', 'fix this', 'solve', 'problem', 'challenge', 'overcome', 'breakthrough', 'game changer', 'this changed everything']
    value_indicators['problem_solutions'] = sum(1 for word in solution_words if word in text_lower)
    
    # –£–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã
    surprise_words = ['surprising', 'shocking', 'unbelievable', 'amazing', 'incredible', 'you won\'t believe', 'most people think', 'contrary to', 'opposite of']
    value_indicators['surprising_facts'] = sum(1 for word in surprise_words if word in text_lower)
    
    # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
    tip_words = ['tip', 'trick', 'hack', 'shortcut', 'faster way', 'easier way', 'better way', 'pro tip', 'life hack', 'quick fix']
    value_indicators['practical_tips'] = sum(1 for word in tip_words if word in text_lower)
    
    # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
    emotion_words = ['excited', 'frustrated', 'angry', 'happy', 'sad', 'disappointed', 'thrilled', 'nervous', 'confident', 'proud', 'embarrassed']
    value_indicators['emotional_moments'] = sum(1 for word in emotion_words if word in text_lower)
    
    total_value_score = sum(value_indicators.values())
    logger.info(f"üíé –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: –æ–±—â–∏–π –±–∞–ª–ª {total_value_score}, —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {sorted(value_indicators.items(), key=lambda x: x[1], reverse=True)[:3]}")
    
    return value_indicators

def identify_key_moments(transcript_text: str) -> List[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ"""
    text_lower = transcript_text.lower()
    
    # –§—Ä–∞–∑—ã, —É–∫–∞–∑—ã–≤–∞—é—â–∏–µ –Ω–∞ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
    key_moment_indicators = [
        'the most important thing',
        'here\'s the key',
        'this is crucial',
        'pay attention to this',
        'this changed everything',
        'the breakthrough moment',
        'the turning point',
        'what i wish i knew',
        'the biggest mistake',
        'the secret is',
        'here\'s what works',
        'the truth about',
        'what nobody tells you',
        'the real reason',
        'this will blow your mind',
        'game changer',
        'life changing',
        'this is huge'
    ]
    
    found_moments = []
    for indicator in key_moment_indicators:
        if indicator in text_lower:
            found_moments.append(indicator)
    
    logger.info(f"üîë –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤: {len(found_moments)} - {found_moments[:5]}")
    return found_moments

def calculate_clip_quality_score(highlight: Dict, transcript_text: str) -> float:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∏–ø–∞ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏"""
    score = 0.0
    
    # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ 45-60 —Å–µ–∫—É–Ω–¥)
    duration = highlight.get("duration", highlight["end_time"] - highlight["start_time"])
    if 45 <= duration <= 60:
        score += 2.0
    elif 30 <= duration <= 75:
        score += 1.5
    else:
        score += 1.0
    
    # –û—Ü–µ–Ω–∫–∞ –∑–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å (–ì–õ–ê–í–ù–´–ô –ö–†–ò–¢–ï–†–ò–ô)
    title = highlight.get("title", "").lower()
    description = highlight.get("description", "").lower()
    hook = highlight.get("hook", "").lower()
    climax = highlight.get("climax", "").lower()
    
    all_text = f"{title} {description} {hook} {climax}"
    
    # –í—ã—Å–æ–∫–æ—Ü–µ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–ø–æ 2 –±–∞–ª–ª–∞ –∫–∞–∂–¥—ã–π)
    high_value_indicators = [
        "how to", "step by step", "secret", "mistake", "avoid", "solution",
        "works", "doesn't work", "key", "important", "crucial", "breakthrough",
        "game changer", "life changing", "truth about", "real reason"
    ]
    high_value_score = sum(2.0 for indicator in high_value_indicators if indicator in all_text)
    score += min(high_value_score, 8.0)  # –ú–∞–∫—Å–∏–º—É–º 8 –±–∞–ª–ª–æ–≤
    
    # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–ø–æ 1.5 –±–∞–ª–ª–∞ –∫–∞–∂–¥—ã–π)
    practical_indicators = [
        "tip", "trick", "hack", "advice", "recommend", "suggest",
        "use this", "try this", "do this", "example", "case study"
    ]
    practical_score = sum(1.5 for indicator in practical_indicators if indicator in all_text)
    score += min(practical_score, 6.0)  # –ú–∞–∫—Å–∏–º—É–º 6 –±–∞–ª–ª–æ–≤
    
    # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å
    emotion = highlight.get("emotion", "neutral").lower()
    emotion_scores = {
        "inspiration": 3.0, "surprise": 2.5, "excitement": 2.5,
        "curiosity": 2.0, "humor": 2.0, "interest": 1.5, "neutral": 0.5
    }
    score += emotion_scores.get(emotion, 1.0)
    
    # –í–∏—Ä—É—Å–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª (–º–µ–Ω—å—à–∏–π –≤–µ—Å, —á–µ–º —Ü–µ–Ω–Ω–æ—Å—Ç—å)
    viral_potential = highlight.get("viral_potential", "medium").lower()
    viral_scores = {"high": 2.0, "medium": 1.0, "low": 0.5}
    score += viral_scores.get(viral_potential, 1.0)
    
    # –ö–∞—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ü–µ–Ω–Ω–æ—Å—Ç—å
    value_words_in_title = sum(1 for word in ["secret", "how", "why", "best", "truth", "mistake", "avoid", "key"] if word in title)
    score += value_words_in_title * 1.0
    
    # –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ—Å—Ç—å
    keywords = highlight.get("keywords", [])
    if len(keywords) >= 3:
        score += 2.0
    elif len(keywords) >= 2:
        score += 1.0
    
    # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ö—É–∫–∞ –∏ –∫—É–ª—å–º–∏–Ω–∞—Ü–∏–∏
    if len(hook) > 20:
        score += 1.5
    if len(climax) > 20:
        score += 1.5
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã
    generic_phrases = ["interesting", "good", "nice", "cool", "awesome"]
    penalty = sum(0.5 for phrase in generic_phrases if phrase in all_text)
    score -= min(penalty, 2.0)
    
    return round(max(score, 0), 2)  # –ú–∏–Ω–∏–º—É–º 0 –±–∞–ª–ª–æ–≤

def analyze_with_chatgpt(transcript_text: str, video_duration: float) -> Optional[Dict]:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º –ø–æ–∏—Å–∫–∞ –∫–ª–∏–ø–æ–≤"""
    try:
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∏–ø–æ–≤ —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏
        if video_duration <= 60:  # –î–æ 1 –º–∏–Ω—É—Ç—ã - —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–π –º–æ–º–µ–Ω—Ç
            target_clips = 1
            min_quality_threshold = 4.0  # –û—á–µ–Ω—å –º—è–≥–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ
            logger.info(f"üìπ –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ ({video_duration}s) - –∏—â–µ–º 1 –ª—É—á—à–∏–π –º–æ–º–µ–Ω—Ç")
        elif video_duration <= 120:  # –î–æ 2 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 2 –∫–ª–∏–ø–∞
            target_clips = 2
            min_quality_threshold = 5.0
            logger.info(f"üìπ –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ ({video_duration}s) - –∏—â–µ–º –¥–æ 2 –∫–ª–∏–ø–æ–≤")
        elif video_duration <= 300:  # –î–æ 5 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 3 –∫–ª–∏–ø–∞
            target_clips = 3
            min_quality_threshold = 6.0
        elif video_duration <= 600:  # –î–æ 10 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 4 –∫–ª–∏–ø–∞
            target_clips = 4
            min_quality_threshold = 6.5
        elif video_duration <= 1200:  # –î–æ 20 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 5 –∫–ª–∏–ø–æ–≤
            target_clips = 5
            min_quality_threshold = 7.0
        elif video_duration <= 1800:  # –î–æ 30 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 6 –∫–ª–∏–ø–æ–≤
            target_clips = 6
            min_quality_threshold = 7.5
        else:  # –ë–æ–ª—å—à–µ 30 –º–∏–Ω—É—Ç - –º–∞–∫—Å–∏–º—É–º 7 –∫–ª–∏–ø–æ–≤
            target_clips = 7
            min_quality_threshold = 8.0
            
        logger.info(f"üéØ –¶–µ–ª—å: {target_clips} –∫–ª–∏–ø–æ–≤ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º {min_quality_threshold} –±–∞–ª–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∏–ø–æ–≤
        min_clip_duration = Config.CLIP_MIN_DURATION
        max_possible_clips = max(1, int(video_duration / (min_clip_duration + 5)))  # +5 —Å–µ–∫ –º–µ–∂–¥—É –∫–ª–∏–ø–∞–º–∏
        
        if target_clips > max_possible_clips:
            target_clips = max_possible_clips
            logger.warning(f"‚ö†Ô∏è –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –¥–ª—è {target_clips} –∫–ª–∏–ø–æ–≤, —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–æ {max_possible_clips}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –≤–∏–¥–µ–æ
        content_type = analyze_content_type(transcript_text)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        value_indicators = analyze_content_value(transcript_text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
        key_moments = identify_key_moments(transcript_text)
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content_strategies = {
            'educational': """
EDUCATIONAL CONTENT STRATEGY:
- Key concepts and their explanations
- Practical examples and case studies
- Step-by-step instructions
- Important conclusions and summaries
- Answers to frequently asked questions
- Demonstrations and proofs
""",
            'entertainment': """
ENTERTAINMENT CONTENT STRATEGY:
- Funniest and brightest moments
- Unexpected twists and surprises
- Emotional peaks (laughter, surprise, delight)
- Interesting stories with climax
- Amusing dialogues and interactions
- High-energy moments
""",
            'business': """
BUSINESS CONTENT STRATEGY:
- Specific advice and strategies
- Success and failure examples
- Numbers, statistics, results
- Insights and revelations
- Practical recommendations
- Motivational moments
""",
            'personal': """
PERSONAL CONTENT STRATEGY:
- Emotional stories and experiences
- Life lessons and wisdom
- Moments of overcoming difficulties
- Personal revelations and insights
- Inspiring moments
- Genuine emotions and feelings
""",
            'tech': """
TECH CONTENT STRATEGY:
- New feature demonstrations
- Complex concepts explained simply
- Practical technology applications
- Comparisons and reviews
- Problem solutions and life hacks
- Future trends and predictions
"""
        }
        
        strategy = content_strategies.get(content_type, content_strategies['personal'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –ø—Ä–æ–º–ø—Ç
        value_context = f"""
CONTENT VALUE ANALYSIS:
- Actionable advice moments: {value_indicators.get('actionable_advice', 0)}
- Specific numbers/data: {value_indicators.get('specific_numbers', 0)}
- Personal stories: {value_indicators.get('personal_stories', 0)}
- Expert insights: {value_indicators.get('expert_insights', 0)}
- Problem solutions: {value_indicators.get('problem_solutions', 0)}
- Surprising facts: {value_indicators.get('surprising_facts', 0)}
- Practical tips: {value_indicators.get('practical_tips', 0)}

KEY MOMENTS DETECTED: {', '.join(key_moments[:10]) if key_moments else 'None detected'}

PRIORITY: Focus on moments with highest value density - where multiple value indicators overlap.
"""
        
        prompt = f"""
You are a world-class content strategist with 10+ years of experience creating viral content that gets millions of views. Your job is to find the MOST VALUABLE moments that will genuinely help, entertain, or inspire the audience.

CONTENT TYPE: {content_type.upper()}
{strategy}

{value_context}

DEEP VALUE ANALYSIS - Find moments that provide:
1. ACTIONABLE INSIGHTS: Specific advice people can immediately use
2. EMOTIONAL BREAKTHROUGHS: Moments that change how people think/feel
3. SURPRISING REVELATIONS: Information that challenges common beliefs
4. PRACTICAL SOLUTIONS: Clear answers to real problems
5. INSPIRATIONAL MOMENTS: Stories that motivate action
6. EXPERT SECRETS: Insider knowledge not commonly known
7. RELATABLE STRUGGLES: Universal experiences people connect with
8. TRANSFORMATION STORIES: Before/after moments showing change

AUDIENCE VALUE FILTERS:
- Will this moment make someone's life better?
- Does this solve a real problem people have?
- Is this information genuinely useful or just entertaining?
- Would someone save/share this with friends?
- Does this provide unique perspective or insight?
- Can viewers apply this knowledge immediately?

Transcript: {transcript_text}

PREMIUM CLIP SELECTION CRITERIA:
1. VALUE DENSITY: Maximum useful information per second
2. IMMEDIATE APPLICABILITY: Viewers can use this knowledge today
3. UNIQUE PERSPECTIVE: Information not available elsewhere
4. EMOTIONAL RESONANCE: Creates genuine connection with audience
5. PROBLEM-SOLUTION FIT: Addresses real pain points
6. SHAREABILITY FACTOR: People will want to share with others
7. MEMORABILITY: Key insights stick in viewer's mind
8. TRANSFORMATION POTENTIAL: Can genuinely improve someone's situation

ADAPTIVE QUALITY REQUIREMENTS (Video: {video_duration:.1f}s, Target: {target_clips} clips):
1. Create UP TO {target_clips} clips - prioritize QUALITY over quantity
2. Duration: {Config.CLIP_MIN_DURATION}-{Config.CLIP_MAX_DURATION} seconds (adapt to video length)
3. For SHORT videos (<2min): Focus on the SINGLE best moment if needed
4. For MEDIUM videos (2-10min): Find 2-4 distinct valuable moments
5. For LONG videos (>10min): Find multiple high-value segments
6. Each clip must provide GENUINE VALUE - not just entertainment
7. Clips must NOT overlap in time
8. Time within 0-{video_duration:.1f} seconds
9. Start with immediate value proposition, end with actionable takeaway
10. REJECT moments that are just filler or low-value content
11. If video is too short for multiple clips, create ONE exceptional clip
12. Better to have fewer HIGH-QUALITY clips than many mediocre ones

TITLE REQUIREMENTS:
- Use ONLY English language
- Maximum 3-5 words for readability
- Use engaging words: "Secret", "Truth About", "How", "Why", "Top", "Best", "Shocking"
- Avoid long sentences
- Make titles intriguing and clickable

GOOD TITLE EXAMPLES:
- "AI Success Secret"
- "Truth About Chatbots"
- "How AI Makes Money"
- "Why Everyone Fears AI"
- "Top Business Mistakes"

Return result STRICTLY in JSON format:
{{
    "highlights": [
        {{
            "start_time": 0,
            "end_time": 55,
            "title": "AI Success Secret",
            "description": "Why this moment will hook viewers and make them watch till the end",
            "hook": "What exactly in the first seconds will grab viewer attention",
            "climax": "Climactic moment or main insight of the clip",
            "viral_potential": "high",
            "emotion": "surprise",
            "keywords": ["AI", "success", "secret"],
            "best_for": ["tiktok", "instagram", "youtube_shorts"]
        }}
    ]
}}
"""
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.7
        )
        content = response.choices[0].message.content.strip()
        if content.startswith('```json'):
            content = content[7:]
        if content.endswith('```'):
            content = content[:-3]
        content = content.strip()
        try:
            result = json.loads(content)
            highlights = result.get("highlights", [])
            
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–ª–∏–ø–æ–≤
            optimized_highlights = []
            for i, highlight in enumerate(highlights):
                duration = highlight["end_time"] - highlight["start_time"]
                
                # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if duration < Config.CLIP_MIN_DURATION:
                    highlight["end_time"] = min(highlight["start_time"] + Config.CLIP_MIN_DURATION, video_duration)
                elif duration > Config.CLIP_MAX_DURATION:
                    highlight["end_time"] = highlight["start_time"] + Config.CLIP_MAX_DURATION
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                highlight["quality_score"] = calculate_clip_quality_score(highlight, transcript_text)
                highlight["duration"] = highlight["end_time"] - highlight["start_time"]
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π
                highlight.setdefault("viral_potential", "medium")
                highlight.setdefault("emotion", "neutral")
                highlight.setdefault("hook", highlight.get("title", ""))
                highlight.setdefault("climax", highlight.get("description", ""))
                highlight.setdefault("best_for", ["youtube_shorts", "tiktok"])
                
                optimized_highlights.append(highlight)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–µ
            optimized_highlights.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ
            high_quality_clips = [clip for clip in optimized_highlights if clip.get("quality_score", 0) >= min_quality_threshold]
            
            if len(high_quality_clips) >= target_clips:
                highlights = high_quality_clips[:target_clips]
                logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(highlights)} –∫–ª–∏–ø–æ–≤ —Å –∫–∞—á–µ—Å—Ç–≤–æ–º {min_quality_threshold}+ –±–∞–ª–ª–æ–≤")
            elif len(high_quality_clips) > 0:
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–ª–∏–ø–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                highlights = high_quality_clips
                logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(highlights)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ –∏–∑ {target_clips} –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö")
            else:
                # –î–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ –∏–ª–∏ –Ω–∏–∑–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - –±–µ—Ä–µ–º –ª—É—á—à–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ
                highlights = optimized_highlights[:min(target_clips, len(optimized_highlights))]
                logger.warning(f"‚ö†Ô∏è –ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –≤–∑—è—Ç—ã {len(highlights)} –ª—É—á—à–∏—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–ª–∏–ø–æ–≤")
                    
            # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º fallback –∫–ª–∏–ø—ã - –ª—É—á—à–µ –º–µ–Ω—å—à–µ, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ
            if len(highlights) < target_clips and video_duration > 300:  # –¢–æ–ª—å–∫–æ –¥–ª—è –≤–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–µ–µ 5 –º–∏–Ω—É—Ç
                logger.warning(f"ChatGPT –≤–µ—Ä–Ω—É–ª {len(highlights)} –∫–ª–∏–ø–æ–≤ –≤–º–µ—Å—Ç–æ {target_clips} –¥–ª—è –¥–ª–∏–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ")
                last_end = highlights[-1]["end_time"] if highlights else 0
                clips_to_add = min(target_clips - len(highlights), 2)  # –ú–∞–∫—Å–∏–º—É–º 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–ª–∏–ø–∞
                
                for i in range(clips_to_add):
                    if last_end + Config.CLIP_MIN_DURATION + 10 <= video_duration:
                        clip_duration = min(Config.CLIP_MAX_DURATION, video_duration - last_end - 10)
                        highlights.append({
                            "start_time": last_end + 10,
                            "end_time": min(last_end + clip_duration, video_duration),
                            "title": f"Additional Moment {len(highlights) + 1}",
                            "description": "Additional valuable moment from the video",
                            "keywords": [],
                            "quality_score": min_quality_threshold - 0.5  # –ß—É—Ç—å –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
                        })
                        last_end = highlights[-1]["end_time"]
            elif len(highlights) < target_clips:
                logger.info(f"üìä –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ: –Ω–∞–π–¥–µ–Ω–æ {len(highlights)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–ª–∏–ø–æ–≤ –∏–∑ {target_clips} –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ")
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            avg_quality = sum(h.get("quality_score", 0) for h in highlights) / len(highlights) if highlights else 0
            high_quality_clips = sum(1 for h in highlights if h.get("quality_score", 0) >= 7.0)
            
            logger.info(f"üéØ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(highlights)} –∫–ª–∏–ø–æ–≤, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_quality:.1f}, –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞: {high_quality_clips}")
            
            return {"highlights": highlights}
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return create_fallback_highlights(video_duration, target_clips)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å ChatGPT: {e}")
        return create_fallback_highlights(video_duration, 3)

def create_fallback_highlights(video_duration: float, target_clips: int) -> Dict:
    """–°–æ–∑–¥–∞–Ω–∏–µ fallback –∫–ª–∏–ø–æ–≤"""
    highlights = []
    clip_duration = (Config.CLIP_MIN_DURATION + Config.CLIP_MAX_DURATION) // 2  # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    gap = 5  # –ë–æ–ª—å—à–∏–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ –º–µ–∂–¥—É –∫–ª–∏–ø–∞–º–∏
    for i in range(target_clips):
        start = i * (clip_duration + gap)
        end = start + clip_duration
        if end > video_duration:
            end = video_duration
            start = max(0, end - clip_duration)
        if start >= video_duration - 5:
            break
        highlights.append({
            "start_time": start,
            "end_time": end,
            "title": f"Clip {i+1}",
            "description": "Automatically generated clip",
            "keywords": []
        })
    return {"highlights": highlights}

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class VideoUploadResponse(BaseModel):
    video_id: str
    filename: str
    size: int
    duration: float

class AnalyzeRequest(BaseModel):
    video_id: str

class ClipGenerateRequest(BaseModel):
    video_id: str
    format_id: str = "9x16"  # 9x16, 16x9, 1x1, 4x5
    style_id: str = "modern"  # modern, neon, fire, elegant

class ClipDataResponse(BaseModel):
    task_id: str
    video_id: str
    format_id: str
    style_id: str
    download_url: str
    highlights: List[Dict]
    transcript: List[Dict]
    video_duration: float

# API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
@app.post("/api/videos/upload", response_model=VideoUploadResponse)
async def upload_video(file: UploadFile = File(...)):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø–∞–º—è—Ç–∏"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
        if not check_memory_limit():
            cleanup_old_files()
            if not check_memory_limit():
                raise HTTPException(status_code=507, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if file.size > Config.MAX_FILE_SIZE:
            raise HTTPException(status_code=413, detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º {Config.MAX_FILE_SIZE // (1024*1024)}MB")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID
        video_id = str(uuid.uuid4())
        filename = f"{video_id}_{file.filename}"
        file_path = os.path.join(Config.UPLOAD_DIR, filename)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —á–∞–Ω–∫–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        with open(file_path, "wb") as buffer:
            while True:
                chunk = await file.read(8192)  # –ß–∏—Ç–∞–µ–º –ø–æ 8KB
                if not chunk:
                    break
                buffer.write(chunk)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ
        duration = get_video_duration(file_path)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–º—è—Ç–∏
        memory_info = get_memory_usage()
        logger.info(f"‚úÖ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {filename}, —Ä–∞–∑–º–µ—Ä: {file.size//1024}KB, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}s, –ø–∞–º—è—Ç—å: {memory_info['process_mb']}MB")
        
        return VideoUploadResponse(
            video_id=video_id,
            filename=filename,
            size=file.size,
            duration=duration
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/videos/analyze")
async def analyze_video(request: AnalyzeRequest, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–µ—Å—É—Ä—Å–æ–≤"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á
        if not check_memory_limit():
            cleanup_old_files()
            if not check_memory_limit():
                raise HTTPException(status_code=507, detail="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        active_tasks = get_active_tasks_count()
        if active_tasks >= Config.MAX_CONCURRENT_TASKS:
            raise HTTPException(status_code=429, detail=f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á ({active_tasks}). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        
        task_id = str(uuid.uuid4())
        
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
        background_tasks.add_task(analyze_video_task, task_id, request.video_id)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
        analysis_tasks[task_id] = {
            "status": "processing",
            "video_id": request.video_id,
            "created_at": datetime.now(),
            "progress": 0
        }
        
        memory_info = get_memory_usage()
        logger.info(f"üîç –ó–∞–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: {request.video_id}, task_id: {task_id}, –ø–∞–º—è—Ç—å: {memory_info['process_mb']}MB, –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á: {active_tasks + 1}")
        
        return {"task_id": task_id, "status": "processing"}
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/videos/{video_id}/status")
async def get_video_status(video_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ"""
    try:
        # –ò—â–µ–º –∑–∞–¥–∞—á—É –ø–æ video_id
        task = None
        task_id = None
        for tid, t in analysis_tasks.items():
            if t["video_id"] == video_id:
                task = t
                task_id = tid
                break
        
        if not task:
            raise HTTPException(status_code=404, detail="–ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        return {
            "task_id": task_id,
            "video_id": video_id,
            "status": task["status"],
            "progress": task.get("progress", 0),
            "result": task.get("result"),
            "error": task.get("error")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/videos/download/{filename}")
async def download_video(filename: str):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞ (–æ—Ä–∏–≥–∏–Ω–∞–ª –∏–ª–∏ –∫–ª–∏–ø)"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –ø–∞–ø–∫–µ –∫–ª–∏–ø–æ–≤
        clip_path = os.path.join(Config.CLIPS_DIR, filename)
        if os.path.exists(clip_path):
            logger.info(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∫–ª–∏–ø–∞: {filename}")
            return FileResponse(
                clip_path,
                media_type="video/mp4",
                filename=filename
            )
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–ª–∏–ø–∞—Ö, –∏—â–µ–º –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –≤–∏–¥–µ–æ
        video_path = os.path.join(Config.UPLOAD_DIR, filename)
        if os.path.exists(video_path):
            logger.info(f"üì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {filename}")
            return FileResponse(
                video_path,
                media_type="video/mp4",
                filename=filename
            )
        
        # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏–≥–¥–µ
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/clips/generate", response_model=ClipDataResponse)
async def generate_clips_data(request: ClipGenerateRequest):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª–∏–ø–æ–≤ —Å –Ω–∞—Ä–µ–∑–∫–æ–π –≤–∏–¥–µ–æ –Ω–∞ –±—ç–∫–µ–Ω–¥–µ (—Å fallback)"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω
        task = None
        for t in analysis_tasks.values():
            if t["video_id"] == request.video_id and t["status"] == "completed":
                task = t
                break
        
        if not task:
            raise HTTPException(status_code=400, detail="–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        result = task["result"]
        
        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –≤–∏–¥–µ–æ
        video_files = [f for f in os.listdir(Config.UPLOAD_DIR) if f.startswith(request.video_id)]
        if not video_files:
            raise HTTPException(status_code=404, detail="–í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        video_path = os.path.join(Config.UPLOAD_DIR, video_files[0])
        video_filename = video_files[0]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º task_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        task_id = str(uuid.uuid4())
        
        logger.info(f"üé¨ –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ –Ω–∞ –∫–ª–∏–ø—ã: {request.video_id}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞—Ä–µ–∑–∞—Ç—å –≤–∏–¥–µ–æ –Ω–∞ –∫–ª–∏–ø—ã
        try:
            clips_data = await cut_video_into_clips(
                video_path=video_path,
                highlights=result["highlights"],
                transcript=result["transcript"],
                video_id=request.video_id,
                format_id=request.format_id
            )
            
            if clips_data and len(clips_data) > 0:
                logger.info(f"‚úÖ –ö–ª–∏–ø—ã —Å–æ–∑–¥–∞–Ω—ã: {len(clips_data)} —à—Ç—É–∫")
                
                return ClipDataResponse(
                    task_id=task_id,
                    video_id=request.video_id,
                    format_id=request.format_id,
                    style_id=request.style_id,
                    download_url="",  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∫–ª–∏–ø–æ–≤
                    highlights=clips_data,  # –î–∞–Ω–Ω—ã–µ –æ –∫–ª–∏–ø–∞—Ö
                    transcript=result["transcript"],
                    video_duration=result["video_duration"]
                )
            else:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–ª–∏–ø—ã")
                
        except Exception as cutting_error:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ: {cutting_error}")
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ä–µ–∂–∏–º (–±–µ–∑ –Ω–∞—Ä–µ–∑–∫–∏)")
            
            # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –Ω–∞—Ä–µ–∑–∫–∏
            download_url = f"/api/videos/download/{video_filename}"
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ö–∞–π–ª–∞–π—Ç–∞ (–±–µ–∑ –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ)
            enhanced_highlights = []
            for i, highlight in enumerate(result["highlights"]):
                clip_subtitles = prepare_clip_subtitles(
                    transcript=result["transcript"],
                    start_time=highlight["start_time"],
                    end_time=highlight["end_time"]
                )
                
                enhanced_highlight = {
                    **highlight,
                    "clip_id": f"{request.video_id}_clip_{i+1}",
                    "video_url": download_url,  # –û–¥–Ω–æ –≤–∏–¥–µ–æ –¥–ª—è –≤—Å–µ—Ö
                    "duration": highlight["end_time"] - highlight["start_time"],
                    "subtitles": clip_subtitles,
                    "format_id": request.format_id,
                    "needs_client_cutting": True  # –§–ª–∞–≥ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
                }
                enhanced_highlights.append(enhanced_highlight)
            
            logger.info(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤ (—Å—Ç–∞—Ä—ã–π —Ä–µ–∂–∏–º): {request.video_id}")
            
            return ClipDataResponse(
                task_id=task_id,
                video_id=request.video_id,
                format_id=request.format_id,
                style_id=request.style_id,
                download_url=download_url,
                highlights=enhanced_highlights,
                transcript=result["transcript"],
                video_duration=result["video_duration"]
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def cut_video_into_clips(video_path: str, highlights: List[Dict], transcript: List[Dict], video_id: str, format_id: str) -> List[Dict]:
    """–ù–∞—Ä–µ–∑–∞–µ—Ç –≤–∏–¥–µ–æ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª–∏–ø—ã"""
    clips_data = []
    
    for i, highlight in enumerate(highlights):
        try:
            clip_id = f"{video_id}_clip_{i+1}"
            clip_filename = f"{clip_id}.mp4"
            clip_path = os.path.join(Config.CLIPS_DIR, clip_filename)
            
            # –ù–∞—Ä–µ–∑–∞–µ–º –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffmpeg
            success = cut_video_segment(
                input_path=video_path,
                output_path=clip_path,
                start_time=highlight["start_time"],
                end_time=highlight["end_time"],
                format_id=format_id
            )
            
            if not success:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Ä–µ–∑–∫–∏ –∫–ª–∏–ø–∞ {clip_id}")
                continue
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–ø–∞
            clip_subtitles = prepare_clip_subtitles(
                transcript=transcript,
                start_time=highlight["start_time"],
                end_time=highlight["end_time"]
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª–∏–ø –≤ Supabase (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            video_url = upload_clip_to_supabase(clip_path, clip_filename)
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–ø–∞
            clip_data = {
                **highlight,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ö–∞–π–ª–∞–π—Ç–∞
                "clip_id": clip_id,
                "video_url": video_url,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL –∏–∑ Supabase –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–π
                "duration": highlight["end_time"] - highlight["start_time"],
                "subtitles": clip_subtitles,
                "format_id": format_id
            }
            
            clips_data.append(clip_data)
            logger.info(f"‚úÖ –ö–ª–∏–ø —Å–æ–∑–¥–∞–Ω: {clip_id} ({clip_data['duration']:.1f}s)")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∏–ø–∞ {i+1}: {e}")
            continue
    
    return clips_data

def cut_video_segment(input_path: str, output_path: str, start_time: float, end_time: float, format_id: str) -> bool:
    """–ù–∞—Ä–µ–∑–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é ffmpeg (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è 512MB RAM)"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
        if not check_memory_limit():
            logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ ffmpeg –¥–æ—Å—Ç—É–ø–µ–Ω
        try:
            subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.error("‚ùå ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ")
            return False
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–µ–∑–∫–∏ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞
        crop_params = get_crop_parameters_for_format(format_id)
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ ffmpeg –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        cmd = [
            "ffmpeg", "-y",  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã
            "-ss", str(start_time),  # –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ (–ü–ï–†–ï–î –≤—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞)
            "-i", input_path,  # –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            "-t", str(end_time - start_time),  # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            "-vf", f"scale={crop_params['width']}:{crop_params['height']}:force_original_aspect_ratio=increase,crop={crop_params['width']}:{crop_params['height']}",
            "-c:v", "libx264",  # –í–∏–¥–µ–æ –∫–æ–¥–µ–∫
            "-c:a", "aac",  # –ê—É–¥–∏–æ –∫–æ–¥–µ–∫
            "-preset", "veryfast",  # –ë—ã—Å—Ç—Ä–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (–∫–æ–º–ø—Ä–æ–º–∏—Å—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ)
            "-crf", "26",  # –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            "-threads", "2",  # –î–≤–∞ –ø–æ—Ç–æ–∫–∞ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            "-avoid_negative_ts", "make_zero",  # –ò–∑–±–µ–≥–∞–µ–º –ø—Ä–æ–±–ª–µ–º —Å —Ç–∞–π–º–∏–Ω–≥–æ–º
            output_path
        ]
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–∞–Ω–¥—É —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∫–ª–∏–ø–æ–≤
        clip_duration = end_time - start_time
        timeout = max(240, clip_duration * Config.FFMPEG_TIMEOUT_MULTIPLIER)  # –ú–∏–Ω–∏–º—É–º 4 –º–∏–Ω—É—Ç—ã –∏–ª–∏ 4x –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–∞
        logger.info(f"üé¨ –ù–∞—Ä–µ–∑–∫–∞ –∫–ª–∏–ø–∞ {clip_duration:.1f}—Å —Å —Ç–∞–π–º–∞—É—Ç–æ–º {timeout}—Å")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
        
        if result.returncode == 0 and os.path.exists(output_path):
            logger.info(f"‚úÖ –í–∏–¥–µ–æ —Å–µ–≥–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω: {output_path}")
            return True
        else:
            logger.warning(f"‚ö†Ô∏è –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –∫–æ–º–∞–Ω–¥—É: {result.stderr}")
            # Fallback: —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏
            simple_cmd = [
                "ffmpeg", "-y",
                "-ss", str(start_time),
                "-i", input_path,
                "-t", str(end_time - start_time),
                "-c", "copy",  # –ö–æ–ø–∏—Ä—É–µ–º –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
                output_path
            ]
            try:
                simple_result = subprocess.run(simple_cmd, capture_output=True, text=True, timeout=timeout//2)
                if simple_result.returncode == 0 and os.path.exists(output_path):
                    logger.info(f"‚úÖ –í–∏–¥–µ–æ —Å–µ–≥–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞): {output_path}")
                    return True
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ ffmpeg (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞): {simple_result.stderr}")
                    return False
            except subprocess.TimeoutExpired:
                logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –¥–∞–∂–µ —Å —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π")
                return False
            
    except subprocess.TimeoutExpired:
        logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –Ω–∞—Ä–µ–∑–∫–µ –≤–∏–¥–µ–æ: {clip_duration:.1f}—Å –∫–ª–∏–ø, —Ç–∞–π–º–∞—É—Ç {timeout}—Å")
        return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Ä–µ–∑–∫–∏ –≤–∏–¥–µ–æ: {e}")
        return False

def get_crop_parameters_for_format(format_id: str) -> Dict[str, int]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–µ–∑–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    formats = {
        "9x16": {"width": 720, "height": 1280},  # TikTok/Instagram Stories
        "16x9": {"width": 1280, "height": 720},  # YouTube/Landscape
        "1x1": {"width": 720, "height": 720},    # Instagram Post
        "4x5": {"width": 720, "height": 900}     # Instagram Portrait
    }
    return formats.get(format_id, formats["9x16"])

def prepare_clip_subtitles(transcript: List[Dict], start_time: float, end_time: float) -> List[Dict]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Å—É–±—Ç–∏—Ç—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª–∏–ø–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    # –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –≤–∫–ª—é—á–∞–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º
    clip_words = []
    for word in transcript:
        word_start = word.get("start", 0)
        word_end = word.get("end", 0)
        
        # –í–∫–ª—é—á–∞–µ–º —Å–ª–æ–≤–æ –µ—Å–ª–∏ –æ–Ω–æ —Ö–æ—Ç—è –±—ã —á–∞—Å—Ç–∏—á–Ω–æ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω
        if (word_start < end_time and word_end > start_time):
            clip_words.append(word)
    
    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(clip_words)} —Å–ª–æ–≤ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ {start_time:.1f}s - {end_time:.1f}s –∏–∑ {len(transcript)} –æ–±—â–∏—Ö —Å–ª–æ–≤")
    
    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞—á–∞–ª–∞ –∫–ª–∏–ø–∞
    adjusted_words = []
    for word in clip_words:
        adjusted_word = {
            **word,
            "start": word.get("start", 0) - start_time,
            "end": word.get("end", 0) - start_time
        }
        adjusted_words.append(adjusted_word)
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤)
    words_per_group = int(os.getenv("SUBTITLES_WORDS_PER_GROUP", "6"))
    subtitles = group_words_into_subtitles(adjusted_words, words_per_group=words_per_group)
    
    logger.info(f"üìù –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(subtitles)} —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –∫–ª–∏–ø–∞ ({start_time:.1f}s - {end_time:.1f}s)")
    
    return subtitles

def group_words_into_subtitles(words: List[Dict], words_per_group: int = 6) -> List[Dict]:
    """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–ª–æ–≤–∞ –≤ —Å—É–±—Ç–∏—Ç—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    subtitles = []
    total_words_processed = 0
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
    use_uppercase = os.getenv("SUBTITLES_UPPERCASE", "true").lower() == "true"
    
    logger.debug(f"üî§ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ {len(words)} —Å–ª–æ–≤ –ø–æ {words_per_group} –≤ –≥—Ä—É–ø–ø–µ, –∑–∞–≥–ª–∞–≤–Ω—ã–µ: {use_uppercase}")
    
    for i in range(0, len(words), words_per_group):
        group = words[i:i + words_per_group]
        
        if group:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –≥—Ä—É–ø–ø—ã –¥–ª—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
            processed_group = []
            group_words = []
            
            for word in group:
                processed_word = word.copy()
                word_text = word.get("word", "")
                
                if use_uppercase and word_text:
                    processed_word["word"] = word_text.upper()
                    group_words.append(word_text.upper())
                else:
                    group_words.append(word_text)
                
                processed_group.append(processed_word)
                total_words_processed += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç —Å—É–±—Ç–∏—Ç—Ä–∞
            subtitle_text = " ".join(group_words)
            
            subtitle = {
                "id": f"subtitle_{i // words_per_group}",
                "start": group[0].get("start", 0),
                "end": group[-1].get("end", 0),
                "text": subtitle_text,
                "words": processed_group  # –î–ª—è –∫–∞—Ä–∞–æ–∫–µ —ç—Ñ—Ñ–µ–∫—Ç–∞
            }
            subtitles.append(subtitle)
            
            logger.debug(f"üìù –°—É–±—Ç–∏—Ç—Ä {len(subtitles)}: '{subtitle_text}' ({subtitle['start']:.1f}s - {subtitle['end']:.1f}s)")
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(subtitles)} —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –∏–∑ {total_words_processed} —Å–ª–æ–≤")
    return subtitles

def diagnose_transcript_issues(transcript_result: Dict) -> None:
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π"""
    logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–ò:")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    if "words" in transcript_result:
        words = transcript_result["words"]
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(words)} —Å–ª–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ word-level")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å–ª–æ–≤
        sample_words = words[:10]
        for i, word in enumerate(sample_words):
            word_text = word.get("word", "N/A")
            start_time = word.get("start", "N/A")
            end_time = word.get("end", "N/A")
            logger.debug(f"  –°–ª–æ–≤–æ {i+1}: '{word_text}' ({start_time}s - {end_time}s)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤
        filler_words = ['um', 'uh', 'yeah', 'like', 'so', 'well', 'okay', 'right']
        found_fillers = []
        for word in words:
            word_text = word.get("word", "").lower().strip()
            if word_text in filler_words:
                found_fillers.append(word_text)
        
        logger.info(f"üé§ –ù–∞–π–¥–µ–Ω–æ –≤—Å—Ç–∞–≤–Ω—ã—Ö —Å–ª–æ–≤: {len(found_fillers)} - {list(set(found_fillers))}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        words_with_time = [w for w in words if w.get("start") is not None and w.get("end") is not None]
        logger.info(f"‚è∞ –°–ª–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏: {len(words_with_time)}/{len(words)}")
        
        if len(words_with_time) < len(words):
            logger.warning(f"‚ö†Ô∏è {len(words) - len(words_with_time)} —Å–ª–æ–≤ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫!")
    
    elif "segments" in transcript_result:
        segments = transcript_result["segments"]
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        total_words = 0
        for segment in segments:
            if "words" in segment:
                total_words += len(segment["words"])
        
        logger.info(f"üìù –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö: {total_words}")
    
    else:
        logger.warning("‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏!")
        logger.info(f"üîë –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏: {list(transcript_result.keys())}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —Ç–µ–∫—Å—Ç
    if "text" in transcript_result:
        text = transcript_result["text"]
        logger.info(f"üìÑ –û–±—â–∏–π —Ç–µ–∫—Å—Ç: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.debug(f"üìÑ –ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞: '{text[:100]}...'")
    
    logger.info("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")

@app.get("/api/videos/{video_id}/export-data")
async def get_export_data(video_id: str):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)"""
    try:
        # –ù–∞—Ö–æ–¥–∏–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é –∑–∞–¥–∞—á—É –∞–Ω–∞–ª–∏–∑–∞
        task = None
        for t in analysis_tasks.values():
            if t["video_id"] == video_id and t["status"] == "completed":
                task = t
                break
        
        if not task:
            raise HTTPException(status_code=400, detail="–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        result = task["result"]
        
        # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –≤–∏–¥–µ–æ
        video_files = [f for f in os.listdir(Config.UPLOAD_DIR) if f.startswith(video_id)]
        if not video_files:
            raise HTTPException(status_code=404, detail="–í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        video_filename = video_files[0]
        
        return {
            "video_id": video_id,
            "video_filename": video_filename,
            "download_url": f"/api/videos/download/{video_filename}",
            "highlights": result["highlights"],
            "transcript": result["transcript"],
            "video_duration": result["video_duration"],
            "analysis_completed_at": task.get("completed_at")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# –§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ
async def analyze_video_task(task_id: str, video_id: str):
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ"""
    try:
        logger.info(f"üîç –ù–∞—á–∞—Ç –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: {video_id}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        analysis_tasks[task_id]["progress"] = 10
        
        # –ù–∞—Ö–æ–¥–∏–º –≤–∏–¥–µ–æ —Ñ–∞–π–ª
        video_files = [f for f in os.listdir(Config.UPLOAD_DIR) if f.startswith(video_id)]
        if not video_files:
            raise Exception("–í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        video_path = os.path.join(Config.UPLOAD_DIR, video_files[0])
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ
        analysis_tasks[task_id]["progress"] = 20
        audio_path = os.path.join(Config.AUDIO_DIR, f"{video_id}.wav")
        if not extract_audio(video_path, audio_path):
            raise Exception("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ")
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
        analysis_tasks[task_id]["progress"] = 50
        transcript_result = safe_transcribe_audio(audio_path)
        if not transcript_result:
            raise Exception("–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        
        # –ê–Ω–∞–ª–∏–∑ —Å ChatGPT
        analysis_tasks[task_id]["progress"] = 80
        video_duration = get_video_duration(video_path)
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        if "words" in transcript_result:
            # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç OpenAI API —Å word-level timestamps
            transcript_text = " ".join([word["word"] for word in transcript_result["words"]])
            transcript_words = transcript_result["words"]
        elif "segments" in transcript_result:
            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
            transcript_text = " ".join([segment["text"] for segment in transcript_result["segments"]])
            transcript_words = []
            for segment in transcript_result["segments"]:
                if "words" in segment:
                    transcript_words.extend(segment["words"])
        else:
            # Fallback - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é
            transcript_text = transcript_result.get("text", "")
            transcript_words = []
        
        logger.info(f"üìù –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ–ª—É—á–µ–Ω: {len(transcript_text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(transcript_words)} —Å–ª–æ–≤")
        
        analysis_result = analyze_with_chatgpt(transcript_text, video_duration)
        if not analysis_result:
            # –°–æ–∑–¥–∞–µ–º fallback —Ö–∞–π–ª–∞–π—Ç—ã
            analysis_result = create_fallback_highlights(video_duration, 3)
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        analysis_tasks[task_id].update({
            "status": "completed",
            "progress": 100,
            "completed_at": datetime.now(),
            "result": {
                "highlights": analysis_result["highlights"],
                "transcript": transcript_words,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–≤–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
                "video_duration": video_duration
            }
        })
        
        logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {video_id}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ {video_id}: {e}")
        analysis_tasks[task_id].update({
            "status": "failed",
            "error": str(e)
        })

def get_crop_parameters(width: int, height: int, format_type: str) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–µ–∑–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    formats = {
        "9:16": {"target_width": 720, "target_height": 1280},
        "16:9": {"target_width": 1280, "target_height": 720},
        "1:1": {"target_width": 720, "target_height": 720},
        "4:5": {"target_width": 720, "target_height": 900}
    }
    target = formats.get(format_type, formats["9:16"])
    scale_x = target["target_width"] / width
    scale_y = target["target_height"] / height
    scale = max(scale_x, scale_y)
    new_width = int(width * scale)
    new_height = int(height * scale)
    crop_x = (new_width - target["target_width"]) // 2
    crop_y = (new_height - target["target_height"]) // 2
    return {
        "width": target["target_width"],
        "height": target["target_height"]
    }

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
import threading
import time

def periodic_cleanup():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
    while True:
        try:
            time.sleep(Config.CLEANUP_INTERVAL)
            memory_info = get_memory_usage()
            
            # –ï—Å–ª–∏ –ø–∞–º—è—Ç—å –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è, –∑–∞–ø—É—Å–∫–∞–µ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
            if memory_info["process_mb"] > (Config.MAX_MEMORY_USAGE // (1024 * 1024)) * 0.8:
                logger.warning(f"‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_info['process_mb']}MB")
                cleaned = cleanup_old_files()
                logger.info(f"üßπ –ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–µ–Ω–æ {cleaned} —Ñ–∞–π–ª–æ–≤")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∏: {e}")

# –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ—á–∏—Å—Ç–∫–∏
cleanup_thread = threading.Thread(target=periodic_cleanup, daemon=True)
cleanup_thread.start()

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è 512MB RAM
    memory_info = get_memory_usage()
    logger.info(f"üöÄ AgentFlow AI Clips v18.6.0 –∑–∞–ø—É—â–µ–Ω!")
    logger.info(f"üíæ –ü–∞–º—è—Ç—å: {memory_info['process_mb']}MB / {memory_info['total_mb']}MB")
    logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è 512MB RAM:")
    logger.info(f"   - –ú–∞–∫—Å–∏–º—É–º —Ñ–∞–π–ª–∞: {Config.MAX_FILE_SIZE // (1024*1024)}MB")
    logger.info(f"   - –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏: {Config.MAX_MEMORY_USAGE // (1024*1024)}MB")
    logger.info(f"   - –ú–∞–∫—Å–∏–º—É–º –∑–∞–¥–∞—á: {Config.MAX_CONCURRENT_TASKS}")
    logger.info(f"   - –û—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–µ: {Config.CLEANUP_INTERVAL // 60} –º–∏–Ω—É—Ç")
    logger.info(f"üìä –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ")
    
    uvicorn.run(app, host="0.0.0.0", port=port)

