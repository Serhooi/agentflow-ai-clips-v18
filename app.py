# AgentFlow AI Clips v18.5.6 - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Remotion –¥–ª—è –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—É–±—Ç–∏—Ç—Ä–æ–≤
import os
import json
import uuid
import asyncio
import logging
import subprocess
import tempfile
from datetime import datetime
from typing import Dict, List, Optional, Any
import psutil
import shutil

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
import openai
from openai import OpenAI

# Supabase Storage –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    logger = logging.getLogger("app")
    logger.warning("Supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("app")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="AgentFlow AI Clips API",
    description="–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤ —Å –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏ —á–µ—Ä–µ–∑ Remotion",
    version="18.5.6"
)

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
class Config:
    UPLOAD_DIR = "uploads"
    AUDIO_DIR = "audio"
    CLIPS_DIR = "clips"
    REMOTION_DIR = "remotion"
    MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB
    MAX_TASK_AGE = 24 * 60 * 60  # 24 —á–∞—Å–∞
    CLEANUP_INTERVAL = 3600  # –û—á–∏—Å—Ç–∫–∞ –∫–∞–∂–¥—ã–π —á–∞—Å
    FPS = 30  # FPS –¥–ª—è Remotion

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–ø–æ–∫
for directory in [Config.UPLOAD_DIR, Config.AUDIO_DIR, Config.CLIPS_DIR, Config.REMOTION_DIR]:
    os.makedirs(directory, exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
analysis_tasks = {}
generation_tasks = {}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    logger.error("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    raise ValueError("OPENAI_API_KEY –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")

client = OpenAI(api_key=openai_api_key)
logger.info("‚úÖ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase
supabase = None
service_supabase = None
SUPABASE_BUCKET = "video-results"

def init_supabase():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–æ–≤"""
    global supabase, service_supabase
    if not SUPABASE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False
    try:
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_anon_key = os.getenv("SUPABASE_ANON_KEY")
        supabase_service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        if not all([supabase_url, supabase_anon_key, supabase_service_key]):
            logger.warning("‚ö†Ô∏è –ù–µ –≤—Å–µ Supabase –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
            return False
        supabase = create_client(supabase_url, supabase_anon_key)
        service_supabase = create_client(supabase_url, supabase_service_key)
        logger.info("‚úÖ Supabase Storage –ø–æ–¥–∫–ª—é—á–µ–Ω")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return False

supabase_available = init_supabase()

# Pydantic –º–æ–¥–µ–ª–∏
class VideoAnalysisRequest(BaseModel):
    video_id: str

class ClipGenerationRequest(BaseModel):
    video_id: str
    format_id: str

class VideoInfo(BaseModel):
    id: str
    filename: str
    duration: float
    size: int
    status: str
    upload_time: str

class ClipInfo(BaseModel):
    id: str
    video_id: str
    format_id: str
    status: str
    progress: int
    current_stage: Optional[str] = None
    stage_progress: Optional[int] = None

def upload_clip_to_supabase(local_path: str, filename: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∏–ø–∞ –≤ Supabase Storage"""
    if not supabase_available or not service_supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å")
        return f"/api/clips/download/{filename}"
    try:
        with open(local_path, "rb") as clip_file:
            storage_path = f"clips/{datetime.now().strftime('%Y%m%d')}/{filename}"
            response = service_supabase.storage.from_(SUPABASE_BUCKET).upload(
                storage_path, clip_file, {"content-type": "video/mp4"}
            )
            if response:
                public_url = service_supabase.storage.from_(SUPABASE_BUCKET).get_public_url(storage_path)
                logger.info(f"‚úÖ –ö–ª–∏–ø –∑–∞–≥—Ä—É–∂–µ–Ω –≤ Supabase: {public_url}")
                return public_url
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Supabase: {e}")
    logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ")
    return f"/api/clips/download/{filename}"

def get_video_duration(video_path: str) -> float:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ"""
    try:
        cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', video_path]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        data = json.loads(result.stdout)
        return float(data['format']['duration'])
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ: {e}")
        return 60.0  # Fallback

def extract_audio(video_path: str, audio_path: str) -> bool:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ"""
    try:
        cmd = ['ffmpeg', '-i', video_path, '-vn', '-acodec', 'mp3', '-ar', '16000', '-ac', '1', '-y', audio_path]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        return os.path.exists(audio_path)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
        return False

def safe_transcribe_audio(audio_path: str) -> Optional[Dict]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ"""
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="verbose_json",
                timestamp_granularities=["word"]
            )
            return transcript.model_dump() if hasattr(transcript, 'model_dump') else dict(transcript)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
        return None

def analyze_with_chatgpt(transcript_text: str, video_duration: float) -> Optional[Dict]:
    """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 3-5 –∫–ª–∏–ø–æ–≤"""
    try:
        target_clips = 2 if video_duration <= 30 else 3 if video_duration <= 60 else 4 if video_duration <= 120 else 5
        prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤–∏–¥–µ–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é {video_duration:.1f} —Å–µ–∫—É–Ω–¥ –∏ –Ω–∞–π–¥–∏ {target_clips} —Å–∞–º—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∫–ª–∏–ø–æ–≤.

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: {transcript_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –°–æ–∑–¥–∞–π –†–û–í–ù–û {target_clips} –∫–ª–∏–ø–æ–≤
2. –ö–∞–∂–¥—ã–π –∫–ª–∏–ø –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 15-20 —Å–µ–∫—É–Ω–¥
3. –ö–ª–∏–ø—ã –ù–ï –¥–æ–ª–∂–Ω—ã –ø–µ—Ä–µ—Å–µ–∫–∞—Ç—å—Å—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
4. –í—ã–±–∏—Ä–∞–π —Å–∞–º—ã–µ —è—Ä–∫–∏–µ, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
5. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –º–∞–ª–æ, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏ –∫–ª–∏–ø—ã –ø–æ –≤—Å–µ–º—É –≤–∏–¥–µ–æ
6. –í—Ä–µ–º—è –∫–ª–∏–ø–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 0-{video_duration:.1f} —Å–µ–∫—É–Ω–¥

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "highlights": [
        {{
            "start_time": 0,
            "end_time": 18,
            "title": "–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫",
            "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è",
            "keywords": ["–∫–ª—é—á–µ–≤–æ–µ", "—Å–ª–æ–≤–æ"]
        }}
    ]
}}
"""
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.7
        )
        content = response.choices[0].message.content.strip()
        if content.startswith('```json'):
            content = content[7:]
        if content.endswith('```'):
            content = content[:-3]
        content = content.strip()
        try:
            result = json.loads(content)
            highlights = result.get("highlights", [])
            if len(highlights) < target_clips:
                logger.warning(f"ChatGPT –≤–µ—Ä–Ω—É–ª {len(highlights)} –∫–ª–∏–ø–æ–≤ –≤–º–µ—Å—Ç–æ {target_clips}")
                last_end = highlights[-1]["end_time"] if highlights else 0
                while len(highlights) < target_clips and last_end + 20 <= video_duration:
                    highlights.append({
                        "start_time": last_end + 2,
                        "end_time": min(last_end + 20, video_duration),
                        "title": f"–ö–ª–∏–ø {len(highlights) + 1}",
                        "description": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∏–ø",
                        "keywords": []
                    })
                    last_end = highlights[-1]["end_time"]
            return {"highlights": highlights}
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return create_fallback_highlights(video_duration, target_clips)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å ChatGPT: {e}")
        return create_fallback_highlights(video_duration, 3)

def create_fallback_highlights(video_duration: float, target_clips: int) -> Dict:
    """–°–æ–∑–¥–∞–Ω–∏–µ fallback –∫–ª–∏–ø–æ–≤"""
    highlights = []
    clip_duration = 18
    gap = 2
    for i in range(target_clips):
        start = i * (clip_duration + gap)
        end = start + clip_duration
        if end > video_duration:
            end = video_duration
            start = max(0, end - clip_duration)
        if start >= video_duration - 5:
            break
        highlights.append({
            "start_time": start,
            "end_time": end,
            "title": f"–ö–ª–∏–ø {i+1}",
            "description": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∫–ª–∏–ø",
            "keywords": []
        })
    return {"highlights": highlights}

def get_crop_parameters(width: int, height: int, format_type: str) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–µ–∑–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    formats = {
        "9:16": {"target_width": 720, "target_height": 1280},
        "16:9": {"target_width": 1280, "target_height": 720},
        "1:1": {"target_width": 720, "target_height": 720},
        "4:5": {"target_width": 720, "target_height": 900}
    }
    target = formats.get(format_type, formats["9:16"])
    scale_x = target["target_width"] / width
    scale_y = target["target_height"] / height
    scale = max(scale_x, scale_y)
    new_width = int(width * scale)
    new_height = int(height * scale)
    crop_x = (new_width - target["target_width"]) // 2
    crop_y = (new_height - target["target_height"]) // 2
    return {
        "width": target["target_width"],
        "height": target["target_height"]
    }

# –°–¢–ê–†–´–ï –§–£–ù–ö–¶–ò–ò REMOTION - –ó–ê–ö–û–ú–ú–ï–ù–¢–ò–†–û–í–ê–ù–´ –î–õ–Ø –§–†–û–ù–¢–ï–ù–î –ü–û–î–•–û–î–ê
# def render_clip_with_remotion(video_path: str, words: List[Dict], start_time: float, end_time: float, output_path: str, format_type: str) -> bool:
#     """–†–µ–Ω–¥–µ—Ä –∫–ª–∏–ø–∞ —Å –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏ —á–µ—Ä–µ–∑ Remotion"""
#     # –§—É–Ω–∫—Ü–∏—è –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ - —Ç–µ–ø–µ—Ä—å —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ

# async def generate_clips_task(task_id: str):
#     """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤"""  
#     # –§—É–Ω–∫—Ü–∏—è –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ - —Ç–µ–ø–µ—Ä—å –∫–ª–∏–ø—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ


# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    logger.info(f"üöÄ AgentFlow AI Clips v18.6.2 started!")
    logger.info(f"üé¨ –§—Ä–æ–Ω—Ç–µ–Ω–¥ –ø–æ–¥—Ö–æ–¥ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω - —Å—É–±—Ç–∏—Ç—Ä—ã –Ω–∞–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ")
    uvicorn.run(app, host="0.0.0.0", port=port)

